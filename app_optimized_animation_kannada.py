import os
import streamlit as st
import streamlit.components.v1 as components
import json
import onnx_asr
from scipy.io import wavfile
import numpy as np
import tempfile
import base64
import time
import soundfile as sf
from pedalboard import Pedalboard, Resample
import sys
import pysqlite3
from datetime import datetime
from dotenv import load_dotenv
from langdetect import detect
from deep_translator import GoogleTranslator


# Import the audio_recorder component
from audio_recorder_streamlit import audio_recorder

# Import gTTS for text-to-speech
from gtts import gTTS

sys.modules["sqlite3"] = pysqlite3

import hashlib

def msg_id_from_text(text: str) -> str:
    return hashlib.sha1((text or "").encode("utf-8")).hexdigest()


def get_image_base64(image_path):
    """Convert image to base64 for embedding in HTML"""
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except Exception as e:
        st.error(f"Error loading image {image_path}: {e}")
        return None

if st.button('Clear Resource Cache'):
    st.cache_resource.clear()
    st.success("Resource cache cleared!")

import asyncio
try:
    asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

import whisper
import torch
from transformers import pipeline

class WhisperASR:
    def __init__(self, model_name: str = "vasista22/whisper-kannada-base"):
        # Use the fine-tuned Kannada Whisper model from Hugging Face
        self.model_name = model_name
        print(f"Loading Whisper model: {model_name}")
        try:
            # Create the ASR pipeline as per the official usage example
            self.transcribe = pipeline(
                task="automatic-speech-recognition",
                model=model_name,
                token=False
            )
            
            # Set the forced decoder IDs for Kannada transcription
            self.transcribe.model.config.forced_decoder_ids = self.transcribe.tokenizer.get_decoder_prompt_ids(
                language="kn", 
                task="transcribe"
            )
                        
        except Exception as e:
            print(f"Error loading fine-tuned model: {e}")
            st.error(e)
            print("Falling back to OpenAI Whisper tiny model...")
            # Fallback to OpenAI Whisper if HF model fails
            self.transcribe = None
            self.fallback_model = whisper.load_model("tiny")

    def recognize(self, audio_path: str) -> str:
        try:
            if self.transcribe is not None:
                # Use Hugging Face Transformers pipeline (preferred method)
                result = self.transcribe(audio_path)
                return result["text"].strip() if result and "text" in result else ""
            else:
                # Fallback to OpenAI Whisper
                result = self.fallback_model.transcribe(audio_path, language='kn', fp16=False)
                return result.get("text", "").strip()
                
        except Exception as e:
            print(f"Error in speech recognition: {e}")
            st.error(e)
            return "[Speech recognition failed]"
        
# Load environment variables
load_dotenv(dotenv_path=".env", override=True)

# Import the EducationalAgent class
try:
    from educational_agent_optimized_langsmith_kannada.agent import EducationalAgent
    from educational_agent_optimized_langsmith_kannada.config import concept_pkg
    from tester_agent.session_metrics import compute_and_upload_session_metrics
except ImportError as e:
    st.error(f"Could not import EducationalAgent: {e}")
    st.stop()
    
# ── ASR & TTS Functions ──────────────────────────────────────────────────
@st.cache_resource(ttl=36000)
def load_asr_model():
    print("BOOT: about to init ASR...", flush=True)
    # Use the fine-tuned Kannada Whisper model
    model = WhisperASR(model_name="vasista22/whisper-kannada-base")
    print("BOOT: ASR ready", flush=True)
    return model

asr_model = load_asr_model()

def convert_to_mono_wav(input_path, output_path):
    try:
        sr, data = wavfile.read(input_path)
        if len(data.shape) == 2:
            data = np.mean(data, axis=1).astype(data.dtype)
        wavfile.write(output_path, sr, data)
    except Exception as e:
        st.error(f"Error converting WAV to mono: {e}")
        st.stop()

def transcribe_recorded_audio_bytes(audio_bytes):
    """Transcribe audio bytes to text using ASR model"""
    if asr_model is None:
        return "[Audio transcription disabled - ASR model not loaded]"
    
    tmp_path = f"temp_recorded_{time.time()}.wav"
    mono_wav_path = f"temp_mono_{time.time()}.wav"
    try:
        with open(tmp_path, 'wb') as f: 
            f.write(audio_bytes)
        convert_to_mono_wav(tmp_path, mono_wav_path)
        return asr_model.recognize(mono_wav_path)
    except Exception as e:
        st.error(f"Error in audio transcription: {e}")
        return "[Audio transcription failed]"
    finally:
        if os.path.exists(tmp_path): 
            os.remove(tmp_path)
        if os.path.exists(mono_wav_path): 
            os.remove(mono_wav_path)

from uuid import uuid4
import streamlit.components.v1 as components

def play_text_as_audio(text, container, message_id=None, speed_factor=1.25):
    """
    gTTS -> speedup with Pedalboard -> WAV playback.
    Also emits postMessage('audio_play'/'audio_end') to the sidebar iframe.
    """
    if not text or not text.strip():
        return

    try:
        # 1) TTS to mp3
        tts = gTTS(text=text, lang='kn', slow=False)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            normal_speed_path = fp.name

        # 2) Read + resample (speed up)
        audio, sample_rate = sf.read(normal_speed_path)
        board = Pedalboard([Resample(target_sample_rate=int(sample_rate * speed_factor))])
        fast_audio = board(audio, sample_rate)

        # 3) Calculate correct duration for sped-up audio
        original_duration_ms = int((len(audio) / float(sample_rate)) * 1000)
        dur_ms = int(original_duration_ms / speed_factor)  # Actual playback duration after speedup
        new_sr = int(sample_rate * speed_factor)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            sf.write(fp.name, fast_audio, new_sr, format='WAV')
            fast_speed_path = fp.name

        # 4) Base64
        with open(fast_speed_path, "rb") as audio_file:
            audio_base64 = base64.b64encode(audio_file.read()).decode("utf-8")

        # 5) Clean up
        os.remove(normal_speed_path)
        os.remove(fast_speed_path)

        # 6) Render with JS hooks. Use components.html so <script> can run.
        msg_id = message_id or str(uuid4())
        audio_html = f"""
        <audio id="agentAudio" controls autoplay style="width: 100%; margin-top: 5px;">
          <source src="data:audio/wav;base64,{audio_base64}" type="audio/wav">
        </audio>
        <script>
          (function() {{
            const SPEED = {speed_factor};
            const DURATION_MS = {dur_ms};
            const MSG_ID = "{msg_id}";
            const a = document.getElementById('agentAudio');
            
            function notify(type) {{
              // Tell ALL parent listeners; sidebar will filter by id.
              window.parent.postMessage({{ type, speed: SPEED, id: MSG_ID, dur: DURATION_MS, ts: Date.now() }}, "*");
            }}
            
            // Better audio ready detection
            a.addEventListener('loadeddata', () => {{
              // Audio is loaded and ready - notify immediately for better sync
              setTimeout(() => notify('audio_play'), 50); // Small delay for browser processing
            }});
            
            a.addEventListener('play',  ()=>notify('audio_play'));
            a.addEventListener('ended', ()=>notify('audio_end'));
            a.addEventListener('pause', ()=>notify('audio_pause'));
          }})();
        </script>
        """
        with container:
            components.html(audio_html, height=80)
        return msg_id

    except Exception as e:
        st.error(f"An error occurred in audio processing: {e}")
        return None

def create_pendulum_simulation_html(config):
    before_params = config['before_params']
    after_params = config['after_params']
    timing = config['timing']
    agent_message = config['agent_message']

    # return f"""
    # <!DOCTYPE html>
    # <html>
    # <head>
    #     <style>
    #         .simulation-container {{
    #             width: 100%;
    #             max-width: 600px;
    #             margin: 10px auto;
    #             background: #f0f6ff;
    #             border: 2px solid #c4afe9;
    #             border-radius: 15px;
    #             padding: 15px;
    #             text-align: center;
    #             position: relative;
    #         }}
    #         .simulation-canvas {{
    #             background: #ede9fe;
    #             border-radius: 12px;
    #             margin: 10px auto;
    #             display: block;
    #         }}
    #         .simulation-controls {{
    #             display: flex;
    #             justify-content: center;
    #             gap: 20px;
    #             margin: 10px 0;
    #             font-family: 'Segoe UI', sans-serif;
    #             flex-wrap: wrap;
    #         }}
    #         .param-display {{
    #             background: rgba(124, 58, 237, 0.1);
    #             padding: 8px 12px;
    #             border-radius: 8px;
    #             font-size: 14px;
    #             font-weight: 500;
    #         }}
    #         .agent-message {{
    #             background: rgba(124, 58, 237, 0.9);
    #             color: white;
    #             padding: 10px 15px;
    #             border-radius: 10px;
    #             margin: 10px 0;
    #             font-size: 16px;
    #             font-weight: 500;
    #         }}
    #         .phase-indicator {{
    #             background: #7c3aed;
    #             color: white;
    #             padding: 5px 15px;
    #             border-radius: 20px;
    #             font-size: 14px;
    #             font-weight: 600;
    #             margin: 10px 0;
    #         }}
    #         .hint-box {{
    #             text-align: left;
    #             background: #ffffff;
    #             border: 1px dashed #7c3aed;
    #             border-radius: 10px;
    #             padding: 10px 12px;
    #             margin-top: 8px;
    #             line-height: 1.5;
    #             color: #333;
    #         }}
    #         .hint-box b {{
    #             color: #7c3aed;
    #         }}
    #         .formula {{
    #             font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    #             background: #f7f2ff;
    #             padding: 2px 6px;
    #             border-radius: 6px;
    #             border: 1px solid #e4d7ff;
    #         }}
    #     </style>
    # </head>
    # <body>
    #     <div class="simulation-container">
    #         <div class="agent-message">{agent_message}</div>
    #         <div id="phase-indicator" class="phase-indicator">Phase: Before Change</div>
            
    #         <canvas id="pendulum-canvas" class="simulation-canvas" width="420" height="320"></canvas>
            
    #         <div class="simulation-controls">
    #             <div class="param-display">
    #                 Length: <span id="length-display">{before_params['length']:.1f}m</span>
    #             </div>
    #             <div class="param-display">
    #                 Gravity: <span id="gravity-display">{before_params['gravity']:.1f} m/s²</span>
    #             </div>
    #             <div class="param-display">
    #                 Amplitude: <span id="amplitude-display">{before_params['amplitude']}°</span>
    #             </div>
    #             <div class="param-display">
    #                 Period ≈ <span id="period-display">—</span> s
    #             </div>
    #         </div>

    #         <div class="hint-box">
    #             <b>Try this:</b>
    #             <ul style="margin:6px 0 0 18px; padding:0;">
    #               <li>Watch how the <b>period</b> (time for one swing) changes as <b>length (L)</b> changes.</li>
    #               <li>Notice that increasing <b>gravity (g)</b> makes the pendulum swing <b>faster</b> (shorter period).</li>
    #               <li>For small angles, the period is approximately <span class="formula">T ≈ 2π √(L / g)</span>. Keep an eye on the live value above!</li>
    #             </ul>
    #         </div>
    #     </div>
        
    #     <script>
    #         const beforeParams = {json.dumps(before_params)};
    #         const afterParams = {json.dumps(after_params)};
    #         const timing = {json.dumps(timing)};
            
    #         const canvas = document.getElementById('pendulum-canvas');
    #         const ctx = canvas.getContext('2d');
    #         const originX = 210, originY = 60;
    #         const baseScale = 80;
            
    #         let currentParams = {{...beforeParams}};
    #         let angle = (currentParams.amplitude * Math.PI) / 180;
    #         let aVel = 0, aAcc = 0;
    #         const dt = 0.02;
    #         let startTime = Date.now();
    #         let phase = 'before';

    #         function smallAnglePeriod(L, g) {{
    #             if (L <= 0 || g <= 0) return NaN;
    #             return 2 * Math.PI * Math.sqrt(L / g);
    #         }}

    #         function updatePhaseIndicator() {{
    #             const indicator = document.getElementById('phase-indicator');
    #             const elapsed = (Date.now() - startTime) / 1000;
                
    #             if (elapsed < timing.before_duration) {{
    #                 indicator.textContent = 'Phase: Before Change';
    #                 phase = 'before';
    #             }} else if (elapsed < timing.before_duration + timing.transition_duration) {{
    #                 indicator.textContent = 'Phase: Changing Parameters...';
    #                 phase = 'transition';
                    
    #                 const transitionProgress = (elapsed - timing.before_duration) / timing.transition_duration;
    #                 const progress = Math.min(transitionProgress, 1);
                    
    #                 currentParams.length = beforeParams.length + (afterParams.length - beforeParams.length) * progress;
    #                 currentParams.gravity = beforeParams.gravity + (afterParams.gravity - beforeParams.gravity) * progress;
    #                 currentParams.amplitude = beforeParams.amplitude + (afterParams.amplitude - beforeParams.amplitude) * progress;
                    
    #                 if (progress === 1) {{
    #                     angle = (currentParams.amplitude * Math.PI) / 180;
    #                     aVel = 0;
    #                 }}
    #             }} else {{
    #                 indicator.textContent = 'Phase: After Change';
    #                 phase = 'after';
    #                 currentParams = {{...afterParams}};
    #             }}
                
    #             document.getElementById('length-display').textContent = currentParams.length.toFixed(1) + 'm';
    #             document.getElementById('gravity-display').textContent = currentParams.gravity.toFixed(1) + ' m/s²';
    #             document.getElementById('amplitude-display').textContent = Math.round(currentParams.amplitude) + '°';

    #             const T = smallAnglePeriod(currentParams.length, currentParams.gravity);
    #             const pd = document.getElementById('period-display');
    #             pd.textContent = isFinite(T) ? T.toFixed(2) : '—';
    #         }}
            
    #         function drawPendulum() {{
    #             ctx.clearRect(0, 0, canvas.width, canvas.height);
                
    #             const lengthPixels = currentParams.length * baseScale;
    #             aAcc = (-currentParams.gravity / currentParams.length) * Math.sin(angle);
    #             aVel += aAcc * dt;
    #             aVel *= 0.998;
    #             angle += aVel * dt;
                
    #             const bobX = originX + lengthPixels * Math.sin(angle);
    #             const bobY = originY + lengthPixels * Math.cos(angle);
                
    #             ctx.beginPath();
    #             ctx.arc(originX, originY, 6, 0, 2 * Math.PI);
    #             ctx.fillStyle = '#7c3aed';
    #             ctx.fill();
                
    #             ctx.beginPath();
    #             ctx.moveTo(originX, originY);
    #             ctx.lineTo(bobX, bobY);
    #             ctx.strokeStyle = '#7c3aed';
    #             ctx.lineWidth = 3;
    #             ctx.stroke();
                
    #             ctx.beginPath();
    #             ctx.arc(bobX, bobY, 15, 0, 2 * Math.PI);
    #             ctx.fillStyle = '#ede9fe';
    #             ctx.strokeStyle = '#7c3aed';
    #             ctx.lineWidth = 2.5;
    #             ctx.fill();
    #             ctx.stroke();
    #         }}
            
    #         function animate() {{
    #             updatePhaseIndicator();
    #             drawPendulum();
    #             requestAnimationFrame(animate);
    #         }}
    #         animate();
    #     </script>
    # </body>
    # </html>
    # """
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <style>
            .simulation-container {{
                width: 100%;
                max-width: 600px;
                margin: 10px auto;
                background: #f0f6ff;
                border: 2px solid #c4afe9;
                border-radius: 15px;
                padding: 15px;
                text-align: center;
                position: relative;
            }}
            .simulation-canvas {{
                background: #ede9fe;
                border-radius: 12px;
                margin: 10px auto;
                display: block;
            }}
            .simulation-controls {{
                display: flex;
                justify-content: center;
                gap: 20px;
                margin: 10px 0;
                font-family: 'Segoe UI', sans-serif;
                flex-wrap: wrap;
            }}
            .param-display {{
                background: rgba(124, 58, 237, 0.1);
                padding: 8px 12px;
                border-radius: 8px;
                font-size: 14px;
                font-weight: 500;
            }}
            .agent-message {{
                background: rgba(124, 58, 237, 0.9);
                color: white;
                padding: 10px 15px;
                border-radius: 10px;
                margin: 10px 0;
                font-size: 16px;
                font-weight: 500;
            }}
            .phase-indicator {{
                background: #7c3aed;
                color: white;
                padding: 5px 15px;
                border-radius: 20px;
                font-size: 14px;
                font-weight: 600;
                margin: 10px 0;
            }}
            .hint-box {{
                text-align: left;
                background: #ffffff;
                border: 1px dashed #7c3aed;
                border-radius: 10px;
                padding: 10px 12px;
                margin-top: 8px;
                line-height: 1.5;
                color: #333;
            }}
            .hint-box b {{
                color: #7c3aed;
            }}
            .formula {{
                font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
                background: #f7f2ff;
                padding: 2px 6px;
                border-radius: 6px;
                border: 1px solid #e4d7ff;
            }}
        </style>
    </head>
    <body>
        <div class="simulation-container">
            <div class="agent-message">{agent_message}</div>
            <div id="phase-indicator" class="phase-indicator">Phase: Before Change</div>
            
            <canvas id="pendulum-canvas" class="simulation-canvas" width="420" height="320"></canvas>
            
            <div class="simulation-controls">
                <div class="param-display">
                    Length: <span id="length-display">{before_params['length']:.1f}m</span>
                </div>
                <div class="param-display">
                    Gravity: <span id="gravity-display">{before_params['gravity']:.1f} m/s²</span>
                </div>
                <div class="param-display">
                    Amplitude: <span id="amplitude-display">{before_params['amplitude']}°</span>
                </div>
                <div class="param-display">
                    Mass: <span id="mass-display">{before_params.get('mass', 1):.2f} kg</span>
                </div>
                <div class="param-display">
                    Period ≈ <span id="period-display">—</span> s
                </div>
            </div>

            <div class="hint-box">
                <b>Try this:</b>
                <ul style="margin:6px 0 0 18px; padding:0;">
                  <li>Watch how the <b>period</b> (time for one swing) changes as <b>length (L)</b> changes.</li>
                  <li>Notice that increasing <b>gravity (g)</b> makes the pendulum swing <b>faster</b> (shorter period).</li>
                  <li>For small angles, the period is approximately <span class="formula">T ≈ 2π √(L / g)</span>. Keep an eye on the live value above!</li>
                </ul>
            </div>
        </div>
        
        <script>
            const beforeParams = {json.dumps(before_params)};
            const afterParams = {json.dumps(after_params)};
            const timing = {json.dumps(timing)};
            
            // ---- MASS DEFAULTS (added) ----
            if (beforeParams.mass === undefined) beforeParams.mass = 1;
            if (afterParams.mass === undefined)  afterParams.mass  = 1;
            // --------------------------------
            
            const canvas = document.getElementById('pendulum-canvas');
            const ctx = canvas.getContext('2d');
            const originX = 210, originY = 60;
            const baseScale = 80;
            
            let currentParams = {{...beforeParams}};
            let angle = (currentParams.amplitude * Math.PI) / 180;
            let aVel = 0, aAcc = 0;
            const dt = 0.02;
            let startTime = Date.now();
            let phase = 'before';

            function smallAnglePeriod(L, g) {{
                if (L <= 0 || g <= 0) return NaN;
                return 2 * Math.PI * Math.sqrt(L / g);
            }}

            function updatePhaseIndicator() {{
                const indicator = document.getElementById('phase-indicator');
                const elapsed = (Date.now() - startTime) / 1000;
                
                if (elapsed < timing.before_duration) {{
                    indicator.textContent = 'Phase: Before Change';
                    phase = 'before';
                }} else if (elapsed < timing.before_duration + timing.transition_duration) {{
                    indicator.textContent = 'Phase: Changing Parameters...';
                    phase = 'transition';
                    
                    const transitionProgress = (elapsed - timing.before_duration) / timing.transition_duration;
                    const progress = Math.min(transitionProgress, 1);
                    
                    currentParams.length    = beforeParams.length    + (afterParams.length    - beforeParams.length)    * progress;
                    currentParams.gravity   = beforeParams.gravity   + (afterParams.gravity   - beforeParams.gravity)   * progress;
                    currentParams.amplitude = beforeParams.amplitude + (afterParams.amplitude - beforeParams.amplitude) * progress;
                    currentParams.mass      = beforeParams.mass      + (afterParams.mass      - beforeParams.mass)      * progress;
                    
                    if (progress === 1) {{
                        angle = (currentParams.amplitude * Math.PI) / 180;
                        aVel = 0;
                    }}
                }} else {{
                    indicator.textContent = 'Phase: After Change';
                    phase = 'after';
                    currentParams = {{...afterParams}};
                }}

                document.getElementById('length-display').textContent    = currentParams.length.toFixed(1) + 'm';
                document.getElementById('gravity-display').textContent   = currentParams.gravity.toFixed(1) + ' m/s²';
                document.getElementById('amplitude-display').textContent = Math.round(currentParams.amplitude) + '°';
                document.getElementById('mass-display').textContent      = (currentParams.mass ?? 1).toFixed(2) + ' kg';

                const T = smallAnglePeriod(currentParams.length, currentParams.gravity);
                const pd = document.getElementById('period-display');
                pd.textContent = isFinite(T) ? T.toFixed(2) : '—';
            }}
            
            function drawPendulum() {{
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                const lengthPixels = currentParams.length * baseScale;
                aAcc = (-currentParams.gravity / currentParams.length) * Math.sin(angle);
                aVel += aAcc * dt;
                aVel *= 0.998;
                angle += aVel * dt;
                
                const bobX = originX + lengthPixels * Math.sin(angle);
                const bobY = originY + lengthPixels * Math.cos(angle);
                
                ctx.beginPath();
                ctx.arc(originX, originY, 6, 0, 2 * Math.PI);
                ctx.fillStyle = '#7c3aed';
                ctx.fill();
                
                ctx.beginPath();
                ctx.moveTo(originX, originY);
                ctx.lineTo(bobX, bobY);
                ctx.strokeStyle = '#7c3aed';
                ctx.lineWidth = 3;
                ctx.stroke();
                
                // ---- MASS VISUALIZATION (added) ----
                // Bob radius grows with mass (visual only); capped for aesthetics
                const m = Math.max(0.1, currentParams.mass || 1);
                const bobRadius = Math.min(12 + 3 * m, 30);
                // ------------------------------------
                
                ctx.beginPath();
                ctx.arc(bobX, bobY, bobRadius, 0, 2 * Math.PI);
                ctx.fillStyle = '#ede9fe';
                ctx.strokeStyle = '#7c3aed';
                ctx.lineWidth = 2.5;
                ctx.fill();
                ctx.stroke();
            }}
            
            function animate() {{
                updatePhaseIndicator();
                drawPendulum();
                requestAnimationFrame(animate);
            }}
            animate();
        </script>
    </body>
    </html>
    """

def display_simulation_if_needed():
    """
    Check if simulation should be displayed and render it.
    Only displays if simulation is active and hasn't been shown for this cycle.
    """
    if (hasattr(st.session_state, 'agent') and 
        st.session_state.agent.state.get("show_simulation")):
        
        simulation_config = st.session_state.agent.state.get("simulation_config")
        
        if simulation_config:
            try:
                # Create and display the simulation
                simulation_html = create_pendulum_simulation_html(simulation_config)
                components.html(simulation_html, height=500)
                
                # Add a brief pause instruction
                st.info("🔬 **Simulation running above** - Watch the pendulum carefully and notice what changes!")
                
                # Mark simulation as displayed but keep it available for this cycle
                # We don't reset show_simulation here - let the nodes manage the lifecycle
                
            except Exception as e:
                st.error(f"Error displaying simulation: {e}")
                # Clear flags on error
                st.session_state.agent.state["show_simulation"] = False
                st.stop()

def display_image_with_context(image_data, show_explanation=True):
    """Enhanced image display with educational context"""
    
    # Main image with responsive sizing
    st.image(
        image_data["url"],
        caption=f"{image_data['description']}",
        use_container_width=False
    )
    
    # Optional: Educational context in an expander
    if show_explanation and image_data.get("relevance_reason"):
        with st.expander(" Why this image helps your learning"):
            st.write(image_data["relevance_reason"])
            
    # Add a subtle divider after image
    st.markdown("---")


def render_viseme_sidebar(latest_text: str, key: str = "viseme_iframe"):
    latest_text = (latest_text or "").strip()

    def js_escape(s):
        return s.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${}")
    safe_text = js_escape(latest_text)

    # Pull the most recent audio's message id (so we sync only to the latest)
    current_msg_id = st.session_state.get('latest_audio_msg_id', "")

    boy_image_path = os.path.join("static", "myphoto2.png")
    girl_image_path = os.path.join("static", "myphoto.png")
    boy_image_b64 = get_image_base64(boy_image_path)
    girl_image_b64 = get_image_base64(girl_image_path)
    if not boy_image_b64 or not girl_image_b64:
        st.error("Could not load character images from static folder")
        return

    html = f"""
    <!doctype html>
    <html>
    <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width,initial-scale=1" />
      <style>
        body {{ background: transparent; color: #eee; font-family: Arial, sans-serif; margin: 0; padding: 0; }}
        .container {{ padding: 8px 6px 2px 6px; }}
        .stage {{ position:relative; display:block; }}
        .character {{ width:100%; max-width:260px; display:block; margin:0 auto; position: relative; z-index: 1; }}
        .mouth-container {{ position:absolute; left:25px; top:145px; width:151px; height:36px; pointer-events:none; z-index: 2; }}
        svg.mouth {{ width:100%; height:100%; }}
        .mouth-set g {{ opacity:0; transition:opacity 80ms ease-out; }}
        .mouth-set g.active {{ opacity:1; }}
        .status {{ margin:6px 0 2px 0; text-align:center; font-size:12px; color:#bbb; }}
      </style>
    </head>
    <body>
      <div class="container">
        <div class="stage">
          <img id="characterImage" src="data:image/png;base64,{boy_image_b64}" class="character" />
          <div class="mouth-container">
            <svg class="mouth" viewBox="-50 -50 100 100">
              <g class="mouth-set" id="mouthSet">
                <g data-viseme="rest" class="active"><path d="M-26 6 q26 10 52 0" fill="#c33" stroke="#000" stroke-width="1"/></g>
                <g data-viseme="closed"><rect x="-30" y="-6" width="60" height="12" rx="6" fill="#9b2b2b"/></g>
                <g data-viseme="wide"><ellipse cx="0" cy="6" rx="42" ry="14" fill="#9b2b2b"/></g>
                <g data-viseme="open"><ellipse cx="0" cy="8" rx="36" ry="22" fill="#9b2b2b"/></g>
                <g data-viseme="round"><ellipse cx="0" cy="6" rx="22" ry="26" fill="#9b2b2b"/></g>
                <g data-viseme="f_v">
                  <path d="M-28 6 q28 -24 56 0" fill="none" stroke="#000" stroke-width="3" />
                  <rect x="-20" y="2" width="40" height="6" rx="3" fill="#9b2b2b" />
                </g>
                <g data-viseme="th">
                  <rect x="-18" y="0" width="36" height="8" rx="4" fill="#9b2b2b" />
                  <rect x="-6" y="-8" width="12" height="8" rx="3" fill="#ffe8d6" />
                </g>
                <g data-viseme="smush"><ellipse cx="0" cy="6" rx="28" ry="12" fill="#9b2b2b"/></g>
                <g data-viseme="kiss"><ellipse cx="0" cy="6" rx="16" ry="12" fill="#9b2b2b"/></g>
              </g>
            </svg>
          </div>
        </div>

        <div class="status">
          <div>Viseme: <strong id="visemeName">rest</strong></div>
        </div>
      </div>

      <script>
        const INJECTED_TEXT = `{safe_text}`;
        const CURRENT_MSG_ID = `{current_msg_id}`;

        const mouthSet = document.getElementById("mouthSet");
        const visemeName = document.getElementById("visemeName");

        let queue = [], timer = null, playing = false, forceStop = false;
        let rateMultiplier = 1.0;       // dynamic: computed per audio
        let watchdog = null;            // hard stop timer
        let lastDurMs = 0;              // last computed duration for fallback

        function simpleG2P(text) {{
          let s = (text || "").toLowerCase().replace(/[^a-z\\s]/g, ' ');
          const tokens = [];
          for (let i=0;i<s.length;) {{
            if (s[i]===" ") {{ i++; continue }}
            const dig=s.slice(i,i+2);
            if (['ch','sh','th','ng','ph','qu','ck','wh'].includes(dig)) {{ tokens.push(dig); i+=2; continue }}
            tokens.push(s[i]); i++;
          }}
          return tokens;
        }}

        function phonemeToViseme(p) {{
          if (['p','b','m'].includes(p)) return 'closed';
          if (['a','o'].includes(p)) return 'open';
          if (['e','i','y'].includes(p)) return 'wide';
          if (['u','oo','w'].includes(p)) return 'round';
          if (['f','v'].includes(p)) return 'f_v';
          if (['th','t','d','n'].includes(p)) return 'th';
          if (['s','z','sh','ch','j'].includes(p)) return 'smush';
          if (['q'].includes(p)) return 'kiss';
          return 'rest';
        }}

        function estimateDur(tok) {{ return /[aeiou]/.test(tok) ? 140 : 90; }}

        function prepareQueue(text) {{
          const toks = simpleG2P(text);
          const frames = toks.map(t=>({{vis:phonemeToViseme(t), dur:estimateDur(t)}}));
          const comp=[];
          for (const f of frames) {{
            const last=comp[comp.length-1];
            if (last && last.vis===f.vis) last.dur+=f.dur;
            else comp.push({{...f}});
          }}
          return comp;
        }}

        function setViseme(v) {{
          mouthSet.querySelectorAll("[data-viseme]").forEach(g=>g.classList.remove("active"));
          const el=mouthSet.querySelector(`[data-viseme="${{v}}"]`);
          if (el) el.classList.add("active");
          visemeName.innerText=v;
        }}

        function stopPlay(hard=false) {{
          playing=false; forceStop=hard; queue=[];
          if (timer) {{ clearTimeout(timer); timer=null; }}
          if (watchdog) {{ clearTimeout(watchdog); watchdog=null; }}
          setViseme("rest");
        }}

        function stepQueue() {{
          if (!playing || forceStop) return;
          if (queue.length===0) {{ setViseme("rest"); playing=false; return; }}
          const frame=queue.shift();
          setViseme(frame.vis);
          const scaled = Math.max(10, Math.round(frame.dur / rateMultiplier));
          lastDurMs += scaled;
          timer = setTimeout(stepQueue, scaled);
        }}

        function totalTextMs(frames) {{
          return frames.reduce((sum,f)=>sum+f.dur, 0);
        }}

        function playVisemes(text, audioMs=null) {{
          stopPlay();
          queue = prepareQueue(text || "");
          const textMs = totalTextMs(queue);
          if (audioMs && isFinite(audioMs) && audioMs > 50) {{
            rateMultiplier = Math.max(0.1, textMs / audioMs); // Scale visemes to match actual audio duration
          }} else {{
            rateMultiplier = 1.25; // fallback: speed up visemes to match 1.25x audio speed
          }}
          lastDurMs = 0;

          if (queue.length>0) {{
            playing=true; stepQueue();
            // Set a watchdog to force-stop when audio should end (with small buffer for precision)
            const wd = audioMs && isFinite(audioMs) && audioMs > 50 ? audioMs : Math.round(textMs / rateMultiplier);
            watchdog = setTimeout(() => stopPlay(true), wd + 100);
          }}
        }}

        // Ensure a mouth is visible even before any audio message arrives
        document.addEventListener('DOMContentLoaded', () => {{
          const el = mouthSet.querySelector('[data-viseme="rest"]');
          if (el) el.classList.add('active');
          visemeName.innerText = 'rest';
        }});

        // Sync via postMessage from the main app audio.
        window.addEventListener("message", (ev) => {{
          const d = ev.data || {{}};
          if (!d || !d.type) return;
          // Only react to the latest message id (avoid stale audio events)
          if (d.id && d.id !== CURRENT_MSG_ID) return;

          if (d.type === 'audio_play') {{
            // Audio is actually playing - this takes priority over fallback
            if (playing) stopPlay(true); // Stop any fallback animation
            const audioMs = d.dur || 0;      // real WAV duration from Python
            playVisemes(INJECTED_TEXT, audioMs);
          }} else if (d.type === 'audio_end' || d.type === 'audio_pause') {{
            stopPlay(true);
          }}
        }});

        // Enhanced fallback with multiple timing checks
        let fallbackAttempts = 0;
        function tryFallback() {{
          fallbackAttempts++;
          if (!playing && fallbackAttempts < 4) {{
            // Check if we should wait longer based on network/processing
            const shouldWait = fallbackAttempts < 3;
            if (shouldWait) {{
              setTimeout(tryFallback, 600 * fallbackAttempts); // Progressive delays: 600ms, 1200ms, 1800ms
              return;
            }}
            
            // Final fallback - start visemes
            const tmp = prepareQueue(INJECTED_TEXT);
            const textMs = totalTextMs(tmp);
            const guessedAudioMs = Math.round(textMs / 1.25);
            playVisemes(INJECTED_TEXT, guessedAudioMs);
          }}
        }}
        
        // Start fallback checks after initial delay
        setTimeout(tryFallback, 800);
      </script>
    </body>
    </html>
    """
    with st.sidebar:
        components.html(html, height=330, scrolling=False)



# ── Streamlit Page Configuration & State Initialization ──────────────────
st.set_page_config(page_title="Interactive Educational Agent", page_icon="🤖")
if "audio_rendered_for_ids" not in st.session_state:
    st.session_state.audio_rendered_for_ids = set()

def generate_session_id():
    """Generate a unique session ID for Langfuse tracking"""
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    return f"streamlit-user-{timestamp}"

def initialize_agent():
    """Initialize the Educational Agent with Langfuse session tracking"""
    session_id = generate_session_id()
    agent = EducationalAgent(
        session_label="streamlit-simulation-session",
        user_id="streamlit-user",
        persona_name="interactive-user"
    )
    return agent, session_id



if "session_started" not in st.session_state:
    st.title("🧑‍🎓 Interactive Simulation Educational Agent")
    st.info(f"Welcome! Ready to learn about **{concept_pkg.title}**? Click 'Start Learning' to begin your personalized learning session.")
    
    if st.button("🚀 Start Learning", type="primary"):
        # Initialize the agent and session
        agent, session_id = initialize_agent()
        
        st.session_state.session_started = True
        st.session_state.agent = agent
        st.session_state.session_id = session_id
        st.session_state.messages = []
        st.session_state.audio_recorder_key_counter = 0
        st.session_state.processing_request = True  # Trigger initial processing for welcome message
        
        st.rerun()
    st.stop()

# ── Step 2: Process a request if the flag is set ───────────────────────────
if st.session_state.get("processing_request"):
    st.session_state.processing_request = False  # Unset flag to prevent re-running

    # Use a spinner during the potentially slow LLM call
    with st.spinner("🤔 Thinking..."):
        try:
            # Check if this is the initial start
            if not st.session_state.messages:
                # Start the conversation
                agent_reply = st.session_state.agent.start()
            else:
                # Continue the conversation with the last user message
                last_user_msg = None
                for message_data in reversed(st.session_state.messages):
                    # Handle both old and new message formats
                    if len(message_data) == 2:
                        role, msg = message_data
                    else:
                        role, msg, _ = message_data
                    
                    if role == "user":
                        last_user_msg = msg
                        break
                
                if last_user_msg:
                    agent_reply = st.session_state.agent.post(last_user_msg)
                else:
                    agent_reply = "I'm waiting for your response."
            
            if agent_reply:
                # Check if there's enhanced metadata from the agent
                if (hasattr(st.session_state.agent, 'state') and 
                    st.session_state.agent.state.get("enhanced_message_metadata")):
                    metadata = st.session_state.agent.state["enhanced_message_metadata"]
                    st.session_state.messages.append(("assistant", agent_reply, metadata))
                    # Clear the metadata after use to prevent duplication
                    st.session_state.agent.state.pop("enhanced_message_metadata", None)
                else:
                    st.session_state.messages.append(("assistant", agent_reply))
        
        except Exception as e:
            st.error(f"An error occurred: {e}")
            agent_reply = "I encountered an error. Please try again."
            st.session_state.messages.append(("assistant", agent_reply))
            st.stop()
    
    st.rerun()

# ── Main Application Logic & UI Display ──────────────────────────────────
st.title("🧑‍🎓 Interactive Simulation Educational Agent")

# Display session info in sidebar
with st.sidebar:
    # 1) VISeme at the very top (latest assistant message)
    last_assistant_text = None
    for message_data in reversed(st.session_state.get("messages", [])):
        # Handle both old and new message formats
        if len(message_data) == 2:
            role, msg = message_data
        else:
            role, msg, _ = message_data
        
        if role == "assistant" and isinstance(msg, str) and msg.strip():
            last_assistant_text = msg
            break

    if last_assistant_text:
        st.session_state['latest_audio_msg_id'] = msg_id_from_text(last_assistant_text)


    if(detect(last_assistant_text) == 'kn'):
        last_assistant_text = GoogleTranslator(source='kn', target='en').translate(last_assistant_text)

    # Render the character (auto-plays on each new assistant msg)
    render_viseme_sidebar(last_assistant_text, key="viseme_iframe_top")

    # 2) The rest of your existing sidebar content
    st.header("📊 Session Info")
    if "agent" in st.session_state:
        session_info = st.session_state.agent.session_info()
        st.write(f"**Session ID:** {session_info['session_id']}")
        st.write(f"**User ID:** {session_info['user_id']}")
        st.write(f"**Current State:** {st.session_state.agent.current_state()}")
        st.write(f"**Concept:** {concept_pkg.title}")
        if session_info.get('tags'):
            st.write(f"**Tags:** {session_info['tags']}")

    st.markdown("---")
    st.markdown("**💡 How to interact:**")
    st.markdown("- Type your responses in the chat input")
    st.markdown("- Or use the microphone to speak")
    st.markdown("- The agent will guide you through learning")


# Display all messages. The audio player is only added for the last assistant message.
for i, message_data in enumerate(st.session_state.messages):
    # Handle both old format (role, content) and new format (role, content, metadata)
    if len(message_data) == 2:  # Old format
        role, msg = message_data
        metadata = {}
    else:  # New format with metadata
        role, msg, metadata = message_data
    
    # Check if message needs translation and update session state
    try:
        detected_lang = detect(msg)
        if detected_lang == 'en':
            translated_msg = GoogleTranslator(source='en', target='kn').translate(msg)
            # Update the message in session state with the translated version
            if len(message_data) == 2:  # Old format
                st.session_state.messages[i] = (role, translated_msg)
            else:  # New format with metadata
                st.session_state.messages[i] = (role, translated_msg, metadata)
            msg = translated_msg
    except Exception as e:
        # If language detection or translation fails, use original message
        st.warning(f"Translation failed for message {i+1}: {e}")
        pass
    
    with st.chat_message(role):
        st.write(msg)
        
        # Display image if present in metadata for assistant messages
        if role == "assistant" and metadata.get("image"):
            display_image_with_context(metadata["image"])
        
        # Check if we need to show simulation after this assistant message
        if role == "assistant" and (i == len(st.session_state.messages) - 1):
            # Display simulation if needed
            display_simulation_if_needed()
            
            # Add audio playback for the latest assistant message (only once per message)
            try:
                # stable id from assistant text so reruns don't create a new id
                mid = msg_id_from_text(msg)

                if mid not in st.session_state.audio_rendered_for_ids:
                    # First render for this assistant reply → create <audio autoplay> + postMessage hooks
                    returned_id = play_text_as_audio(
                        msg,
                        st.container(),
                        message_id=mid,          # keep the id stable across reruns
                        speed_factor=1.25        # your audio speed-up
                    )
                    st.session_state.audio_rendered_for_ids.add(mid)
                    st.session_state['latest_audio_msg_id'] = returned_id  # same as mid
                else:
                    # Already rendered this audio; DO NOT create a new <audio> element (prevents restart)
                    # Just keep the id for the viseme sidebar to know what to sync to
                    st.session_state['latest_audio_msg_id'] = mid

            except Exception as e:
                st.caption("⚠️ Audio playback unavailable")
                st.stop()

            # pass

# Handle user input at the bottom of the page
if "agent" in st.session_state and st.session_state.agent.current_state() != "END":
    user_msg = None
    
    # Audio input
    col1, col2 = st.columns([3, 1])
    with col2:
        st.caption("🎤 Voice Input")
        recorded_audio_bytes = audio_recorder(
            text="Click to speak",
            key=f"audio_recorder_{st.session_state.audio_recorder_key_counter}",
            icon_size="1x", 
            pause_threshold=2.0
        )
        
    if recorded_audio_bytes:
        with st.spinner("🎯 Transcribing..."):
            user_msg = transcribe_recorded_audio_bytes(recorded_audio_bytes)
            if user_msg and not user_msg.startswith("["):  # Valid transcription
                st.success(f"You said: {user_msg}")

    # Text input
    text_input = st.chat_input("💬 Type your response here...")
    if text_input:
        user_msg = text_input

    # ── Step 1: Acknowledge user input and trigger the "Safe State" rerun ──
    if user_msg and not user_msg.startswith("["):  # Valid user input
        st.session_state.audio_recorder_key_counter += 1
        
        # Add user's message and set the flag to process it on the next run
        st.session_state.messages.append(("user", user_msg))
        st.session_state.processing_request = True
        
        # This rerun is fast. It redraws the page without the old audio player.
        st.rerun()

# Session End Summary
if "agent" in st.session_state and st.session_state.agent.current_state() == "END":
    st.markdown("---")
    st.success("🎉 Learning Session Complete!")
    
    # Get session summary from agent state
    session_summary = st.session_state.agent.state.get("session_summary", {})
    
    if session_summary:
        st.subheader("📋 Session Summary")
        st.json(session_summary)
        
        # Download session summary
        summary_json = json.dumps(session_summary, indent=2)
        st.download_button(
            label="📥 Download Session Summary", 
            data=summary_json, 
            file_name=f"session_summary_{st.session_state.session_id}.json", 
            mime="application/json"
        )
    else:
        st.info("Session completed successfully!")
    
    # Show session info for Langfuse tracking
    if "agent" in st.session_state:
        session_info = st.session_state.agent.session_info()
        st.subheader("🔍 Langfuse Session Details")
        st.code(f"Session ID: {session_info['session_id']}\nThread ID: {session_info['thread_id']}")
    
    # Compute and upload session metrics
    if "session_metrics_computed" not in st.session_state:
        with st.spinner("📊 Computing session metrics..."):
            try:
                # Convert messages to history format for metrics
                history_for_reports = st.session_state.agent.get_history_for_reports()
                
                session_metrics = compute_and_upload_session_metrics(
                    session_id=st.session_state.agent.session_id,
                    history=history_for_reports,
                    session_state=st.session_state.agent.state,
                    persona_name="interactive-user"
                )
                st.session_state.session_metrics = session_metrics
                st.session_state.session_metrics_computed = True
                st.success("✅ Session metrics computed and uploaded to Langfuse!")
            except Exception as e:
                st.error(f"❌ Failed to compute metrics: {e}")
                st.session_state.session_metrics_computed = True  # Mark as attempted to avoid retry
    
    # Display computed metrics
    if "session_metrics" in st.session_state:
        st.subheader("📊 Session Metrics")
        metrics = st.session_state.session_metrics
        
        # Key metrics in columns
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Quiz Score", f"{metrics.quiz_score:.1f}%")
            st.metric("User Type", metrics.user_type)
        with col2:
            st.metric("Engagement Rating", f"{metrics.user_engagement_rating:.1f}/5")
            st.metric("Interest Rating", f"{metrics.user_interest_rating:.1f}/5")
        with col3:
            st.metric("Concepts Covered", metrics.num_concepts_covered)
            st.metric("Enjoyment Probability", f"{metrics.enjoyment_probability:.0%}")
        
        # Download metrics
        metrics_json = metrics.model_dump_json(indent=2)
        st.download_button(
            label="📊 Download Session Metrics",
            data=metrics_json,
            file_name=f"session_metrics_{st.session_state.session_id}.json",
            mime="application/json"
        )
    
    # Option to start a new session
    if st.button("🔄 Start New Session", type="primary"):
        # Clear session state
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# Footer
st.markdown("---")
st.caption("🤖 Powered by Educational AI Agent | 📊 Tracked with Langfuse")
