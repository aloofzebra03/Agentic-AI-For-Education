"""
Understanding Evaluator Node
============================
Analyzes student responses to determine their understanding level.

This node uses the LLM to:
1. FIRST: Classify the response type (answer, question, param_request)
2. THEN: If answer, evaluate understanding level
3. Extract relevant info (questions asked, params requested)

The evaluation is nuanced - it's not just right/wrong, but a spectrum.
"""

import json
import re
from typing import Dict, Any
from datetime import datetime

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage

from config import GOOGLE_API_KEY, GEMINI_MODEL, TEMPERATURE, INITIAL_PARAMS
from state import add_message_to_history


def get_llm():
    """Get configured LLM instance."""
    return ChatGoogleGenerativeAI(
        model=GEMINI_MODEL,
        google_api_key=GOOGLE_API_KEY,
        temperature=0.3  # Lower temperature for more consistent evaluation
    )


def parse_json_safe(text: str) -> dict:
    """Extract JSON from LLM response."""
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    
    code_block_match = re.search(r'```(?:json)?\s*([\s\S]*?)```', text)
    if code_block_match:
        try:
            return json.loads(code_block_match.group(1).strip())
        except json.JSONDecodeError:
            pass
    
    json_match = re.search(r'\{[\s\S]*\}', text)
    if json_match:
        try:
            return json.loads(json_match.group())
        except json.JSONDecodeError:
            pass
    
    return {"response_type": "answer", "level": "partial", "reasoning": "Could not parse evaluation"}


def understanding_evaluator_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify and evaluate the student's response.
    
    STEP 1: Classify response type
        - answer: Student is answering the teacher's question
        - question: Student is asking a question
        - param_request: Student wants to change simulation parameters
        
    STEP 2: Based on type, extract relevant info
        - answer â†’ evaluate understanding level
        - question â†’ extract the question for teacher to answer
        - param_request â†’ extract parameter and value
    """
    print("\n" + "="*60)
    print("ðŸ” EVALUATOR NODE: Classifying & Assessing")
    print("="*60)
    
    student_response = state.get("student_response", "")
    
    if not student_response:
        print("   âš ï¸ No student response to evaluate")
        return {
            "understanding_level": "none",
            "understanding_reasoning": "Student hasn't responded yet",
            "response_type": "answer"
        }
    
    # Get current concept
    concepts = state.get("concepts", [])
    current_idx = state.get("current_concept_index", 0)
    current_params = state.get("current_params", INITIAL_PARAMS)
    
    if current_idx >= len(concepts):
        return {
            "understanding_level": "complete",
            "understanding_reasoning": "All concepts completed",
            "response_type": "answer"
        }
    
    current_concept = concepts[current_idx]
    last_teacher_msg = state.get("last_teacher_message", "")
    
    print(f"   Student said: \"{student_response[:100]}...\"" if len(student_response) > 100 else f"   Student said: \"{student_response}\"")
    
    # Build the combined classification + evaluation prompt
    eval_prompt = f"""You are analyzing a student's response in a physics teaching session.

CURRENT SIMULATION PARAMETERS:
- length: {current_params.get('length', 5)} (valid range: 1-10)
- number_of_oscillations: {current_params.get('number_of_oscillations', 10)} (valid range: 5-50)

CONCEPT BEING TAUGHT:
Title: {current_concept['title']}
Key Insight: {current_concept['key_insight']}

TEACHER'S LAST MESSAGE:
"{last_teacher_msg}"

STUDENT'S RESPONSE:
"{student_response}"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 1: CLASSIFY THE RESPONSE TYPE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

First, determine what TYPE of response this is:

1. "answer" - Student is answering/responding to the teacher's question
   Examples: "slower", "I think it takes longer", "don't know", "faster"

2. "question" - Student is ASKING a question or requesting explanation
   Examples: "What's the formula?", "Can you explain again?", "Why does that happen?", "What is time period?"

3. "param_request" - Student wants to CHANGE simulation parameters
   Examples: "Change length to 3", "Set it to 5 units", "Make it shorter", "Try with 20 oscillations"
   NOTE: Student may request MULTIPLE params at once like "change length to 5 and oscillations to 20"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 2: BASED ON TYPE, FILL RELEVANT FIELDS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IF response_type == "answer":
- Evaluate understanding level (none/partial/mostly/complete)
- Check if factually wrong

IF response_type == "question":
- Extract the question being asked
- Set level to current understanding (don't change it)

IF response_type == "param_request":
- Extract which parameter (length or number_of_oscillations)
- Extract the requested value
- Validate it's in range
- Set level to current understanding (don't change it)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
UNDERSTANDING LEVELS (only for "answer" type):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- "complete": Correct answer WITH explanation of WHY
- "mostly": Correct answer but NO reasoning (observation only)
- "partial": Vague, unclear, or just acknowledgment ("okay", "sure")
- "none": "I don't know", off-topic, OR **FACTUALLY WRONG**

âš ï¸ CRITICAL: WRONG ANSWERS = NONE
If student states something factually incorrect (opposite of the concept), level = "none"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPOND WITH ONLY THIS JSON:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```json
{{
    "response_type": "answer" or "question" or "param_request",
    
    // For ALL types:
    "level": "none/partial/mostly/complete",
    "reasoning": "Brief explanation of classification and evaluation",
    
    // For "answer" type:
    "is_factually_wrong": true/false,
    "needs_deeper": true/false,
    "what_they_got_right": "what was correct, empty if wrong",
    
    // For "question" type:
    "question_asked": "The question the student is asking",
    
    // For "param_request" type (can have BOTH if student requested multiple):
    "param_requested": "length" or "number_of_oscillations" or "both" or null,
    "param_value": number or null,
    "param_valid": true/false,
    "length_value": number or null (if length was requested),
    "oscillations_value": number or null (if oscillations was requested)
}}
```
"""

    llm = get_llm()
    response = llm.invoke([HumanMessage(content=eval_prompt)])
    
    result = parse_json_safe(response.content)
    
    # Extract response type (default to "answer")
    response_type = result.get("response_type", "answer")
    valid_types = ["answer", "question", "param_request"]
    if response_type not in valid_types:
        response_type = "answer"
    
    print(f"\n   ðŸ“‹ Response Type: {response_type.upper()}")
    
    # Handle based on response type
    level = result.get("level", "partial")
    reasoning = result.get("reasoning", "Evaluation uncertain")
    needs_deeper = result.get("needs_deeper", False)
    is_factually_wrong = result.get("is_factually_wrong", False)
    
    # Validate level
    valid_levels = ["none", "partial", "mostly", "complete"]
    if level not in valid_levels:
        level = "partial"
    
    # Initialize output
    output = {
        "response_type": response_type,
        "understanding_level": level,
        "understanding_reasoning": reasoning,
    }
    
    if response_type == "answer":
        # Normal answer evaluation
        print(f"   ðŸ“Š Understanding Level: {level.upper()}")
        print(f"   ðŸ“ Reasoning: {reasoning}")
        
        if is_factually_wrong:
            print(f"   âŒ Factually Wrong: Student stated something incorrect")
        if needs_deeper:
            print(f"   ðŸ”„ Needs Deeper: Yes (correct observation, asking for WHY)")
        
        output["is_factually_wrong"] = is_factually_wrong
        output["needs_deeper"] = needs_deeper
        output["_eval_details"] = {
            "what_they_got_right": result.get("what_they_got_right", ""),
            "what_needs_work": result.get("what_needs_work", ""),
            "misconception": result.get("detected_misconception")
        }
        
        # Update trajectory for answers
        old_trajectory = state.get("understanding_trajectory", [])
        output["understanding_trajectory"] = old_trajectory + [level]
        
    elif response_type == "question":
        # Student asked a question
        question_asked = result.get("question_asked", student_response)
        print(f"   â“ Question Asked: {question_asked}")
        
        output["student_asked_question"] = True
        output["question_asked"] = question_asked
        # Don't update trajectory for questions
        output["understanding_trajectory"] = state.get("understanding_trajectory", [])
        
    elif response_type == "param_request":
        # Student requested parameter change
        param = result.get("param_requested")
        value = result.get("param_value")
        is_valid = result.get("param_valid", False)
        
        print(f"   ðŸŽ›ï¸ Parameter Request: {param} = {value}")
        print(f"   âœ“ Valid: {is_valid}")
        
        output["student_requested_param"] = True
        output["requested_param"] = param
        output["requested_value"] = value
        output["param_request_valid"] = is_valid
        
        # If valid, update the params
        if is_valid and param and value is not None:
            new_params = current_params.copy()
            new_params[param] = value
            output["current_params"] = new_params
            print(f"   âœ… Updating params: {param} â†’ {value}")
        
        # Don't update trajectory for param requests
        output["understanding_trajectory"] = state.get("understanding_trajectory", [])
    
    # Add student message to history (for all types)
    student_message = add_message_to_history(state, "student", student_response)
    output["conversation_history"] = state.get("conversation_history", []) + [student_message]
    
    # Update parameter history if exists (for answers)
    if response_type == "answer":
        param_history = state.get("parameter_history", [])
        if param_history:
            param_history[-1]["student_reaction"] = student_response[:200]
            param_history[-1]["understanding_after"] = level
            
            before = param_history[-1].get("understanding_before", "none")
            level_order = {"none": 0, "partial": 1, "mostly": 2, "complete": 3}
            if level_order.get(level, 0) > level_order.get(before, 0):
                param_history[-1]["was_effective"] = True
        output["parameter_history"] = param_history
    
    return output
